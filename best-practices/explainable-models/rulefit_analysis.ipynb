{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RuleFit Analysis\n",
    "\n",
    "The goal of the notebook is to use machine learning to automatically create a set of rules to predict a target column.  The rules provide an explainable solution.\n",
    "\n",
    "## Steps\n",
    "\n",
    "1. Import and clean data\n",
    "2. Train rule-fit model\n",
    "3. Examine rules\n",
    "\n",
    "## Step 1. Import and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"12.0.2\" 2019-07-16; Java(TM) SE Runtime Environment (build 12.0.2+10); Java HotSpot(TM) 64-Bit Server VM (build 12.0.2+10, mixed mode, sharing)\n",
      "  Starting server from /Users/megankurka/env/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/fk/z2fjbsq163scfcsq9fhsw7r00000gn/T/tmpyxhp4yeq\n",
      "  JVM stdout: /var/folders/fk/z2fjbsq163scfcsq9fhsw7r00000gn/T/tmpyxhp4yeq/h2o_megankurka_started_from_python.out\n",
      "  JVM stderr: /var/folders/fk/z2fjbsq163scfcsq9fhsw7r00000gn/T/tmpyxhp4yeq/h2o_megankurka_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>01 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/New_York</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.28.0.3</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>14 days, 2 hours and 40 minutes </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_megankurka_eyjsuh</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>4 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>16</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>{'http': None, 'https': None}</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.8 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------------------------------\n",
       "H2O cluster uptime:         01 secs\n",
       "H2O cluster timezone:       America/New_York\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.28.0.3\n",
       "H2O cluster version age:    14 days, 2 hours and 40 minutes\n",
       "H2O cluster name:           H2O_from_python_megankurka_eyjsuh\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    4 Gb\n",
       "H2O cluster total cores:    16\n",
       "H2O cluster allowed cores:  16\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:       {'http': None, 'https': None}\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python version:             3.6.8 final\n",
       "--------------------------  ------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  pclass</th><th style=\"text-align: right;\">  survived</th><th>name                                           </th><th>sex   </th><th style=\"text-align: right;\">    age</th><th style=\"text-align: right;\">  sibsp</th><th style=\"text-align: right;\">  parch</th><th style=\"text-align: right;\">  ticket</th><th style=\"text-align: right;\">    fare</th><th>cabin  </th><th>embarked  </th><th style=\"text-align: right;\">  boat</th><th style=\"text-align: right;\">  body</th><th>home.dest                      </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         1</td><td>Allen  Miss. Elisabeth Walton                  </td><td>female</td><td style=\"text-align: right;\">29     </td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">   24160</td><td style=\"text-align: right;\">211.338 </td><td>B5     </td><td>S         </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">   nan</td><td>St Louis  MO                   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         1</td><td>Allison  Master. Hudson Trevor                 </td><td>male  </td><td style=\"text-align: right;\"> 0.9167</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">  113781</td><td style=\"text-align: right;\">151.55  </td><td>C22 C26</td><td>S         </td><td style=\"text-align: right;\">    11</td><td style=\"text-align: right;\">   nan</td><td>Montreal  PQ / Chesterville  ON</td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         0</td><td>Allison  Miss. Helen Loraine                   </td><td>female</td><td style=\"text-align: right;\"> 2     </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">  113781</td><td style=\"text-align: right;\">151.55  </td><td>C22 C26</td><td>S         </td><td style=\"text-align: right;\">   nan</td><td style=\"text-align: right;\">   nan</td><td>Montreal  PQ / Chesterville  ON</td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         0</td><td>Allison  Mr. Hudson Joshua Creighton           </td><td>male  </td><td style=\"text-align: right;\">30     </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">  113781</td><td style=\"text-align: right;\">151.55  </td><td>C22 C26</td><td>S         </td><td style=\"text-align: right;\">   nan</td><td style=\"text-align: right;\">   135</td><td>Montreal  PQ / Chesterville  ON</td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         0</td><td>Allison  Mrs. Hudson J C (Bessie Waldo Daniels)</td><td>female</td><td style=\"text-align: right;\">25     </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">  113781</td><td style=\"text-align: right;\">151.55  </td><td>C22 C26</td><td>S         </td><td style=\"text-align: right;\">   nan</td><td style=\"text-align: right;\">   nan</td><td>Montreal  PQ / Chesterville  ON</td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         1</td><td>Anderson  Mr. Harry                            </td><td>male  </td><td style=\"text-align: right;\">48     </td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">   19952</td><td style=\"text-align: right;\"> 26.55  </td><td>E12    </td><td>S         </td><td style=\"text-align: right;\">     3</td><td style=\"text-align: right;\">   nan</td><td>New York  NY                   </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         1</td><td>Andrews  Miss. Kornelia Theodosia              </td><td>female</td><td style=\"text-align: right;\">63     </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">   13502</td><td style=\"text-align: right;\"> 77.9583</td><td>D7     </td><td>S         </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">   nan</td><td>Hudson  NY                     </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         0</td><td>Andrews  Mr. Thomas Jr                         </td><td>male  </td><td style=\"text-align: right;\">39     </td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">  112050</td><td style=\"text-align: right;\">  0     </td><td>A36    </td><td>S         </td><td style=\"text-align: right;\">   nan</td><td style=\"text-align: right;\">   nan</td><td>Belfast  NI                    </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         1</td><td>Appleton  Mrs. Edward Dale (Charlotte Lamson)  </td><td>female</td><td style=\"text-align: right;\">53     </td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">   11769</td><td style=\"text-align: right;\"> 51.4792</td><td>C101   </td><td>S         </td><td style=\"text-align: right;\">   nan</td><td style=\"text-align: right;\">   nan</td><td>Bayside  Queens  NY            </td></tr>\n",
       "<tr><td style=\"text-align: right;\">       1</td><td style=\"text-align: right;\">         0</td><td>Artagaveytia  Mr. Ramon                        </td><td>male  </td><td style=\"text-align: right;\">71     </td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">      0</td><td style=\"text-align: right;\">     nan</td><td style=\"text-align: right;\"> 49.5042</td><td>       </td><td>C         </td><td style=\"text-align: right;\">   nan</td><td style=\"text-align: right;\">    22</td><td>Montevideo  Uruguay            </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = h2o.import_file(\"https://s3.amazonaws.com/h2o-public-test-data/smalldata/gbm_test/titanic.csv\",\n",
    "                    col_types = {'pclass': \"enum\", 'survived': \"enum\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Train Rule-Fit Model\n",
    "\n",
    "We will train a rule-fit model to predict the survival.  The outcome of the rulefit model is rules defining whether or not someone will survive.  The rulefit model is done with the following steps:\n",
    "\n",
    "1. Train a series of random forest models with different depths\n",
    "2. Extract rules from the random forest models\n",
    "3. Train a GLM model with Lasso regularization using the rules to predict the target. \n",
    "4. Extract the most important rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "def h2o_rulefit(training_frame, x, y, seed = None, min_depth = 1, max_depth = 10):\n",
    "    \n",
    "    family = \"gaussian\"\n",
    "    if (training_frame.type(y) == \"enum\"):\n",
    "        if training_frame[y].unique().nrow > 2:\n",
    "            return \"Multinomial Not Supported\"\n",
    "        else:\n",
    "            family = \"binomial\"\n",
    "        \n",
    "    \n",
    "    # Get paths from random forest models\n",
    "    paths_frame = training_frame[y]\n",
    "    depths = range(min_depth, max_depth + 1)\n",
    "    rf_models = []\n",
    "    for model_idx in range(len(depths)):\n",
    "        \n",
    "        # Train random forest models\n",
    "        from h2o.estimators.random_forest import H2ORandomForestEstimator\n",
    "        rf_model = H2ORandomForestEstimator(seed = seed, model_id = \"rf.hex\", max_depth = depths[model_idx])\n",
    "        rf_model.train(y = y, x = x, training_frame = training_frame)\n",
    "        rf_models = rf_models + [rf_model]\n",
    "    \n",
    "        paths = rf_model.predict_leaf_node_assignment(training_frame)\n",
    "        paths.col_names = [\"rf_\" + str(model_idx) +\".\"+ x for x in paths.col_names]\n",
    "        paths_frame = paths_frame.cbind(paths)\n",
    "    \n",
    "    # Extract important paths\n",
    "    from h2o.estimators import H2OGeneralizedLinearEstimator\n",
    "    glm = H2OGeneralizedLinearEstimator(model_id = \"glm.hex\", nfolds = 5, seed = seed,\n",
    "                                        family = family,\n",
    "                                        alpha = 1, remove_collinear_columns=True,\n",
    "                                        lambda_search = True)\n",
    "    glm.train(y = y, training_frame=paths_frame)\n",
    "    \n",
    "    import pandas as pd\n",
    "    rule_importance = pd.DataFrame.from_dict(get_rule_importance(glm), orient = \"index\").reset_index()\n",
    "    rule_importance.columns = [\"variable\", \"coefficient\"]\n",
    "    \n",
    "    # Convert paths to rules\n",
    "    from h2o.tree import H2OTree\n",
    "    rules = []\n",
    "    for i in rule_importance.variable:\n",
    "        if family == \"binomial\":\n",
    "            model_num, tree_num, path = i.replace(\"rf_\", \"\").replace(\"T\", \"\").replace(\"C1.\", \"\").split(\".\")\n",
    "        else:\n",
    "            model_num, tree_num, path = i.replace(\"rf_\", \"\").replace(\"T\", \"\").split(\".\")\n",
    "        tree = H2OTree(rf_models[int(model_num)], int(tree_num)-1)\n",
    "        rules = rules + [tree_traverser(tree.root_node, path)]\n",
    "\n",
    "    # Add rules and order by absolute coefficient\n",
    "    rule_importance[\"rule\"] = rules\n",
    "    rule_importance[\"abs_coefficient\"] = rule_importance[\"coefficient\"].abs()\n",
    "    rule_importance = rule_importance.loc[rule_importance.groupby([\"rule\"])[\"abs_coefficient\"].idxmax()]  \n",
    "    rule_importance = rule_importance.sort_values(by = \"abs_coefficient\", ascending = False)\n",
    "    rule_importance = rule_importance.drop(\"abs_coefficient\", axis = 1)\n",
    "    \n",
    "    return rule_importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rule_importance(glm):\n",
    "    from h2o.estimators import H2OGeneralizedLinearEstimator\n",
    "    \n",
    "    r = H2OGeneralizedLinearEstimator.getGLMRegularizationPath(glm)\n",
    "    deviance = r.get('explained_deviance_train')\n",
    "    inflection_pt = [i*3 for i, x in enumerate(np.diff(np.sign(np.diff(deviance, 2)))) if x != 0 and i > 0][0]\n",
    "    return {k: v for k,v in r.get('coefficients')[inflection_pt].items() if abs(v) > 0 and k != \"Intercept\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_traverser(node, split_path):\n",
    "    rule = []\n",
    "    splits = [char for char in split_path]\n",
    "    for i in splits:\n",
    "        if i == \"R\":\n",
    "            if np.isnan(node.threshold):\n",
    "                rule = rule + [{'split_feature': node.split_feature, \n",
    "                                'value': node.right_levels, \n",
    "                                'operator': 'in'}]\n",
    "            else:\n",
    "                rule = rule + [{'split_feature': node.split_feature, \n",
    "                                'value': node.threshold, \n",
    "                                'operator': '>='}]\n",
    "\n",
    "            node = node.right_child\n",
    "        if i == \"L\":\n",
    "            if np.isnan(node.threshold):\n",
    "                rule = rule + [{'split_feature': node.split_feature, \n",
    "                                'value': node.left_levels, \n",
    "                                'operator': 'in'}]\n",
    "\n",
    "            else:\n",
    "                rule = rule + [{'split_feature': node.split_feature, \n",
    "                                'value': node.threshold, \n",
    "                                'operator': '<'}]\n",
    "\n",
    "            node = node.left_child\n",
    "    consolidated_rules = consolidate_rules(rule)\n",
    "    consolidated_rules = \" AND \".join(consolidated_rules.values())\n",
    "    return consolidated_rules\n",
    "\n",
    "def consolidate_rules(rules):\n",
    "    rules = [x for x in rules if x.get(\"value\")]\n",
    "    features = set([x.get('split_feature') for x in rules])\n",
    "    consolidated_rules = {}\n",
    "    for i in features:\n",
    "        feature_rules = [x for x in rules if x.get('split_feature') == i]\n",
    "        if feature_rules[0].get('operator') == 'in':\n",
    "            cleaned_rules = i + \" is in \" + \", \".join(sum([x.get('value') for x in feature_rules], []))\n",
    "        else:\n",
    "            cleaned_rules = []\n",
    "            operators = set([x.get('operator') for x in feature_rules])\n",
    "            for op in operators:\n",
    "                vals = [x.get('value') for x in feature_rules if x.get('operator') == op]\n",
    "                if '>' in op:\n",
    "                    constraint = max(vals)\n",
    "                else:\n",
    "                    constraint = min(vals)\n",
    "                cleaned_rules = \" and \".join([op + \" \" + str(round(constraint, 3))])\n",
    "                cleaned_rules = i + \" \" + cleaned_rules\n",
    "        consolidated_rules[i] = cleaned_rules\n",
    "    \n",
    "    return consolidated_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = df.split_frame(seed = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "drf Model Build progress: |███████████████████████████████████████████████| 100%\n",
      "glm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "x =  [\"age\", \"sibsp\", \"parch\", \"fare\", \"sex\", \"pclass\"]\n",
    "rules = h2o_rulefit(train, x, \"survived\", seed = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient:0.690245852462075\n",
      "Rule: pclass is in 1, 2 AND sex is in female\n",
      "\n",
      "\n",
      "Coefficient:-0.558256963724828\n",
      "Rule: age >= 8.536 AND sex is in male\n",
      "\n",
      "\n",
      "Coefficient:0.322959683244595\n",
      "Rule: sex is in female AND sibsp < 2.5\n",
      "\n",
      "\n",
      "Coefficient:-0.210309346937613\n",
      "Rule: pclass is in 2, 3 AND sex is in male AND age >= 9.569\n",
      "\n",
      "\n",
      "Coefficient:-0.13832082963874\n",
      "Rule: fare < 52.033 AND pclass is in 2, 3 AND sex is in male AND age >= 5.141\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(rules)):\n",
    "    print(\"Coefficient:\" + str(round(rules.iloc[i][\"coefficient\"], 15)) + \"\\nRule: \" + rules.iloc[i][\"rule\"] + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only 5 rules that are created which are recapped below: \n",
    "\n",
    "**Highest Likelihood of Survival**\n",
    "\n",
    "1. Women in class 1 or 2\n",
    "2. Women with 2 siblings + spouses or less\n",
    "\n",
    "**Lowest Likelihood of Survival**\n",
    "1. Men age 9+\n",
    "2. Men age 10+ in class 2 or 3\n",
    "3. Men 6+ in class 2 or 3 with fare < $52\n",
    "\n",
    "Note: The rules are additive.  That means that if a passenger is described by multiple rules, their probability is added together from those rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2O session _sid_abec closed.\n"
     ]
    }
   ],
   "source": [
    "h2o.cluster().shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
