{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Custom Metric Function In Binary Classification\n",
    "\n",
    "In this notebook, we will show an example of how to calculate custom performance metrics on an H2O model for binary classification. The notebook will go through the following steps:\n",
    "\n",
    "1. Train a GBM model in H2O\n",
    "2. Write a script to calculate cost matrix based loss\n",
    "3. Train a GBM model in H2O using this loss function as a [`custom_metric_func`](https://github.com/h2oai/h2o-3/blob/master/h2o-docs/src/dev/custom_functions.md)\n",
    "4. Train a Grid of GBMs and choose model based on this loss function\n",
    "\n",
    "\n",
    "## 1. Train a  GBM Model in H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: java version \"1.8.0_181\"; Java(TM) SE Runtime Environment (build 1.8.0_181-b13); Java HotSpot(TM) 64-Bit Server VM (build 25.181-b13, mixed mode)\n",
      "  Starting server from /anaconda3/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /var/folders/wk/m00ydfj52f9fl7zvx5cjztgc0000gn/T/tmpib3zvce7\n",
      "  JVM stdout: /var/folders/wk/m00ydfj52f9fl7zvx5cjztgc0000gn/T/tmpib3zvce7/h2o_patrickaboyoun_started_from_python.out\n",
      "  JVM stderr: /var/folders/wk/m00ydfj52f9fl7zvx5cjztgc0000gn/T/tmpib3zvce7/h2o_patrickaboyoun_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/Los_Angeles</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.20.0.7</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>9 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_patrickaboyoun_rxle0j</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>3.556 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.6 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------------\n",
       "H2O cluster uptime:         02 secs\n",
       "H2O cluster timezone:       America/Los_Angeles\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.20.0.7\n",
       "H2O cluster version age:    9 days\n",
       "H2O cluster name:           H2O_from_python_patrickaboyoun_rxle0j\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    3.556 Gb\n",
       "H2O cluster total cores:    8\n",
       "H2O cluster allowed cores:  8\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.6 final\n",
       "--------------------------  ----------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load H2O library\n",
    "import h2o\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Import Data\n",
    "train_path = \"https://raw.githubusercontent.com/h2oai/app-consumer-loan/master/data/loan.csv\"\n",
    "train = h2o.import_file(train_path, destination_frame = \"loan_train\")\n",
    "train[\"bad_loan\"] = train[\"bad_loan\"].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set target and predictor variables\n",
    "y = \"bad_loan\"\n",
    "x = train.col_names\n",
    "x.remove(y)\n",
    "x.remove(\"int_rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Train GBM Model\n",
    "from h2o.estimators import H2OGradientBoostingEstimator\n",
    "\n",
    "gbm_v1 = H2OGradientBoostingEstimator(model_id = \"gbm_v1.hex\")\n",
    "\n",
    "gbm_v1.train(y = y, x = x, training_frame = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  gbm_v1.hex\n",
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.1363951465191071\n",
      "RMSE: 0.3693171354257843\n",
      "LogLoss: 0.43467809200204266\n",
      "Mean Per-Class Error: 0.3508577460272526\n",
      "AUC: 0.7079429892082825\n",
      "Gini: 0.41588597841656494\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.19860658480443358: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>95113.0</td>\n",
       "<td>38858.0</td>\n",
       "<td>0.29</td>\n",
       "<td> (38858.0/133971.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>12401.0</td>\n",
       "<td>17615.0</td>\n",
       "<td>0.4131</td>\n",
       "<td> (12401.0/30016.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>107514.0</td>\n",
       "<td>56473.0</td>\n",
       "<td>0.3126</td>\n",
       "<td> (51259.0/163987.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0       1      Error    Rate\n",
       "-----  ------  -----  -------  ------------------\n",
       "0      95113   38858  0.29     (38858.0/133971.0)\n",
       "1      12401   17615  0.4131   (12401.0/30016.0)\n",
       "Total  107514  56473  0.3126   (51259.0/163987.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.1986066</td>\n",
       "<td>0.4073350</td>\n",
       "<td>228.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1265125</td>\n",
       "<td>0.5633597</td>\n",
       "<td>311.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.2803267</td>\n",
       "<td>0.3837915</td>\n",
       "<td>152.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4292597</td>\n",
       "<td>0.8203272</td>\n",
       "<td>62.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.7770519</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0438524</td>\n",
       "<td>1.0</td>\n",
       "<td>396.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.7770519</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2251476</td>\n",
       "<td>0.2462816</td>\n",
       "<td>202.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1823683</td>\n",
       "<td>0.6488206</td>\n",
       "<td>245.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1920415</td>\n",
       "<td>0.6491423</td>\n",
       "<td>235.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.198607     0.407335  228\n",
       "max f2                       0.126512     0.56336   311\n",
       "max f0point5                 0.280327     0.383791  152\n",
       "max accuracy                 0.42926      0.820327  62\n",
       "max precision                0.777052     1         0\n",
       "max recall                   0.0438524    1         396\n",
       "max specificity              0.777052     1         0\n",
       "max absolute_mcc             0.225148     0.246282  202\n",
       "max min_per_class_accuracy   0.182368     0.648821  245\n",
       "max mean_per_class_accuracy  0.192041     0.649142  235"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 18.30 %, avg score: 18.31 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100008</td>\n",
       "<td>0.4806708</td>\n",
       "<td>3.5211761</td>\n",
       "<td>3.5211761</td>\n",
       "<td>0.6445122</td>\n",
       "<td>0.5303616</td>\n",
       "<td>0.6445122</td>\n",
       "<td>0.5303616</td>\n",
       "<td>0.0352146</td>\n",
       "<td>0.0352146</td>\n",
       "<td>252.1176084</td>\n",
       "<td>252.1176084</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200016</td>\n",
       "<td>0.4375856</td>\n",
       "<td>2.8082795</td>\n",
       "<td>3.1647278</td>\n",
       "<td>0.5140244</td>\n",
       "<td>0.4573837</td>\n",
       "<td>0.5792683</td>\n",
       "<td>0.4938727</td>\n",
       "<td>0.0280850</td>\n",
       "<td>0.0632996</td>\n",
       "<td>180.8279507</td>\n",
       "<td>216.4727796</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300024</td>\n",
       "<td>0.4110619</td>\n",
       "<td>2.6750278</td>\n",
       "<td>3.0014945</td>\n",
       "<td>0.4896341</td>\n",
       "<td>0.4234982</td>\n",
       "<td>0.5493902</td>\n",
       "<td>0.4704145</td>\n",
       "<td>0.0267524</td>\n",
       "<td>0.0900520</td>\n",
       "<td>167.5027810</td>\n",
       "<td>200.1494467</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400032</td>\n",
       "<td>0.3902679</td>\n",
       "<td>2.5117945</td>\n",
       "<td>2.8790695</td>\n",
       "<td>0.4597561</td>\n",
       "<td>0.4001474</td>\n",
       "<td>0.5269817</td>\n",
       "<td>0.4528477</td>\n",
       "<td>0.0251199</td>\n",
       "<td>0.1151719</td>\n",
       "<td>151.1794482</td>\n",
       "<td>187.9069471</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500040</td>\n",
       "<td>0.3731066</td>\n",
       "<td>2.3019231</td>\n",
       "<td>2.7636402</td>\n",
       "<td>0.4213415</td>\n",
       "<td>0.3814565</td>\n",
       "<td>0.5058537</td>\n",
       "<td>0.4385695</td>\n",
       "<td>0.0230211</td>\n",
       "<td>0.1381930</td>\n",
       "<td>130.1923060</td>\n",
       "<td>176.3640189</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000018</td>\n",
       "<td>0.3147513</td>\n",
       "<td>2.0763146</td>\n",
       "<td>2.4199984</td>\n",
       "<td>0.3800463</td>\n",
       "<td>0.3412588</td>\n",
       "<td>0.4429538</td>\n",
       "<td>0.3899171</td>\n",
       "<td>0.1038113</td>\n",
       "<td>0.2420043</td>\n",
       "<td>107.6314643</td>\n",
       "<td>141.9998372</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1499997</td>\n",
       "<td>0.2770929</td>\n",
       "<td>1.7224882</td>\n",
       "<td>2.1875044</td>\n",
       "<td>0.3152824</td>\n",
       "<td>0.2946252</td>\n",
       "<td>0.4003984</td>\n",
       "<td>0.3581544</td>\n",
       "<td>0.0861207</td>\n",
       "<td>0.328125</td>\n",
       "<td>72.2488239</td>\n",
       "<td>118.7504446</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000037</td>\n",
       "<td>0.2503682</td>\n",
       "<td>1.5570461</td>\n",
       "<td>2.0298802</td>\n",
       "<td>0.285</td>\n",
       "<td>0.2631637</td>\n",
       "<td>0.3715470</td>\n",
       "<td>0.3344053</td>\n",
       "<td>0.0778585</td>\n",
       "<td>0.4059835</td>\n",
       "<td>55.7046075</td>\n",
       "<td>102.9880242</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2999994</td>\n",
       "<td>0.2116632</td>\n",
       "<td>1.2990293</td>\n",
       "<td>1.7862732</td>\n",
       "<td>0.2377729</td>\n",
       "<td>0.2298703</td>\n",
       "<td>0.3269575</td>\n",
       "<td>0.2995617</td>\n",
       "<td>0.1298974</td>\n",
       "<td>0.5358809</td>\n",
       "<td>29.9029331</td>\n",
       "<td>78.6273176</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000012</td>\n",
       "<td>0.1833189</td>\n",
       "<td>1.0747405</td>\n",
       "<td>1.6083873</td>\n",
       "<td>0.1967193</td>\n",
       "<td>0.1968137</td>\n",
       "<td>0.2943974</td>\n",
       "<td>0.2738743</td>\n",
       "<td>0.1074760</td>\n",
       "<td>0.6433569</td>\n",
       "<td>7.4740466</td>\n",
       "<td>60.8387287</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5000030</td>\n",
       "<td>0.1606487</td>\n",
       "<td>0.9334851</td>\n",
       "<td>1.4734052</td>\n",
       "<td>0.1708641</td>\n",
       "<td>0.1716489</td>\n",
       "<td>0.2696905</td>\n",
       "<td>0.2534290</td>\n",
       "<td>0.0933502</td>\n",
       "<td>0.7367071</td>\n",
       "<td>-6.6514945</td>\n",
       "<td>47.3405194</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5999988</td>\n",
       "<td>0.1407404</td>\n",
       "<td>0.7786180</td>\n",
       "<td>1.3576120</td>\n",
       "<td>0.1425174</td>\n",
       "<td>0.1504536</td>\n",
       "<td>0.2484958</td>\n",
       "<td>0.2362671</td>\n",
       "<td>0.0778585</td>\n",
       "<td>0.8145656</td>\n",
       "<td>-22.1382009</td>\n",
       "<td>35.7612035</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000006</td>\n",
       "<td>0.1230032</td>\n",
       "<td>0.6626345</td>\n",
       "<td>1.2583278</td>\n",
       "<td>0.1212879</td>\n",
       "<td>0.1318218</td>\n",
       "<td>0.2303229</td>\n",
       "<td>0.2213461</td>\n",
       "<td>0.0662647</td>\n",
       "<td>0.8808302</td>\n",
       "<td>-33.7365534</td>\n",
       "<td>25.8327795</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7999963</td>\n",
       "<td>0.1056462</td>\n",
       "<td>0.5434001</td>\n",
       "<td>1.1689652</td>\n",
       "<td>0.0994633</td>\n",
       "<td>0.1142765</td>\n",
       "<td>0.2139661</td>\n",
       "<td>0.2079629</td>\n",
       "<td>0.0543377</td>\n",
       "<td>0.9351679</td>\n",
       "<td>-45.6599939</td>\n",
       "<td>16.8965234</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999982</td>\n",
       "<td>0.0862040</td>\n",
       "<td>0.4147712</td>\n",
       "<td>1.0851642</td>\n",
       "<td>0.0759193</td>\n",
       "<td>0.0963432</td>\n",
       "<td>0.1986273</td>\n",
       "<td>0.1955604</td>\n",
       "<td>0.0414779</td>\n",
       "<td>0.9766458</td>\n",
       "<td>-58.5228803</td>\n",
       "<td>8.5164193</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0315070</td>\n",
       "<td>0.2335378</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0427465</td>\n",
       "<td>0.0711412</td>\n",
       "<td>0.1830389</td>\n",
       "<td>0.1831183</td>\n",
       "<td>0.0233542</td>\n",
       "<td>1.0</td>\n",
       "<td>-76.6462161</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100008                   0.480671           3.52118   3.52118            0.644512         0.530362   0.644512                    0.530362            0.0352146       0.0352146                  252.118   252.118\n",
       "    2        0.0200016                   0.437586           2.80828   3.16473            0.514024         0.457384   0.579268                    0.493873            0.028085        0.0632996                  180.828   216.473\n",
       "    3        0.0300024                   0.411062           2.67503   3.00149            0.489634         0.423498   0.54939                     0.470414            0.0267524       0.090052                   167.503   200.149\n",
       "    4        0.0400032                   0.390268           2.51179   2.87907            0.459756         0.400147   0.526982                    0.452848            0.0251199       0.115172                   151.179   187.907\n",
       "    5        0.050004                    0.373107           2.30192   2.76364            0.421341         0.381456   0.505854                    0.438569            0.0230211       0.138193                   130.192   176.364\n",
       "    6        0.100002                    0.314751           2.07631   2.42               0.380046         0.341259   0.442954                    0.389917            0.103811        0.242004                   107.631   142\n",
       "    7        0.15                        0.277093           1.72249   2.1875             0.315282         0.294625   0.400398                    0.358154            0.0861207       0.328125                   72.2488   118.75\n",
       "    8        0.200004                    0.250368           1.55705   2.02988            0.285            0.263164   0.371547                    0.334405            0.0778585       0.405983                   55.7046   102.988\n",
       "    9        0.299999                    0.211663           1.29903   1.78627            0.237773         0.22987    0.326957                    0.299562            0.129897        0.535881                   29.9029   78.6273\n",
       "    10       0.400001                    0.183319           1.07474   1.60839            0.196719         0.196814   0.294397                    0.273874            0.107476        0.643357                   7.47405   60.8387\n",
       "    11       0.500003                    0.160649           0.933485  1.47341            0.170864         0.171649   0.26969                     0.253429            0.0933502       0.736707                   -6.65149  47.3405\n",
       "    12       0.599999                    0.14074            0.778618  1.35761            0.142517         0.150454   0.248496                    0.236267            0.0778585       0.814566                   -22.1382  35.7612\n",
       "    13       0.700001                    0.123003           0.662634  1.25833            0.121288         0.131822   0.230323                    0.221346            0.0662647       0.88083                    -33.7366  25.8328\n",
       "    14       0.799996                    0.105646           0.5434    1.16897            0.0994633        0.114276   0.213966                    0.207963            0.0543377       0.935168                   -45.66    16.8965\n",
       "    15       0.899998                    0.086204           0.414771  1.08516            0.0759193        0.0963432  0.198627                    0.19556             0.0414779       0.976646                   -58.5229  8.51642\n",
       "    16       1                           0.031507           0.233538  1                  0.0427465        0.0711412  0.183039                    0.183118            0.0233542       1                          -76.6462  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-09-10 13:51:02</td>\n",
       "<td> 0.022 sec</td>\n",
       "<td>0.0</td>\n",
       "<td>0.3866984</td>\n",
       "<td>0.4759704</td>\n",
       "<td>0.5</td>\n",
       "<td>1.0</td>\n",
       "<td>0.8169611</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-09-10 13:51:02</td>\n",
       "<td> 0.764 sec</td>\n",
       "<td>1.0</td>\n",
       "<td>0.3847635</td>\n",
       "<td>0.4710759</td>\n",
       "<td>0.6582899</td>\n",
       "<td>2.5923891</td>\n",
       "<td>0.3376304</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-09-10 13:51:03</td>\n",
       "<td> 1.026 sec</td>\n",
       "<td>2.0</td>\n",
       "<td>0.3831611</td>\n",
       "<td>0.4671624</td>\n",
       "<td>0.6641427</td>\n",
       "<td>2.7218454</td>\n",
       "<td>0.3575466</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-09-10 13:51:03</td>\n",
       "<td> 1.278 sec</td>\n",
       "<td>3.0</td>\n",
       "<td>0.3818189</td>\n",
       "<td>0.4639557</td>\n",
       "<td>0.6658226</td>\n",
       "<td>2.8447858</td>\n",
       "<td>0.3506497</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-09-10 13:51:03</td>\n",
       "<td> 1.387 sec</td>\n",
       "<td>4.0</td>\n",
       "<td>0.3806812</td>\n",
       "<td>0.4612690</td>\n",
       "<td>0.6685973</td>\n",
       "<td>2.9280752</td>\n",
       "<td>0.3523572</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-09-10 13:51:05</td>\n",
       "<td> 3.608 sec</td>\n",
       "<td>23.0</td>\n",
       "<td>0.3725708</td>\n",
       "<td>0.4423727</td>\n",
       "<td>0.6931526</td>\n",
       "<td>3.2979795</td>\n",
       "<td>0.3413929</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-09-10 13:51:05</td>\n",
       "<td> 3.731 sec</td>\n",
       "<td>24.0</td>\n",
       "<td>0.3724149</td>\n",
       "<td>0.4419880</td>\n",
       "<td>0.6938720</td>\n",
       "<td>3.2979795</td>\n",
       "<td>0.3356547</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-09-10 13:51:06</td>\n",
       "<td> 3.887 sec</td>\n",
       "<td>25.0</td>\n",
       "<td>0.3722080</td>\n",
       "<td>0.4415065</td>\n",
       "<td>0.6947887</td>\n",
       "<td>3.3079734</td>\n",
       "<td>0.3273674</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-09-10 13:51:06</td>\n",
       "<td> 4.015 sec</td>\n",
       "<td>26.0</td>\n",
       "<td>0.3720656</td>\n",
       "<td>0.4411389</td>\n",
       "<td>0.6955963</td>\n",
       "<td>3.3312924</td>\n",
       "<td>0.3317702</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2018-09-10 13:51:07</td>\n",
       "<td> 5.497 sec</td>\n",
       "<td>50.0</td>\n",
       "<td>0.3693171</td>\n",
       "<td>0.4346781</td>\n",
       "<td>0.7079430</td>\n",
       "<td>3.5211761</td>\n",
       "<td>0.3125797</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration    number_of_trees    training_rmse        training_logloss     training_auc        training_lift       training_classification_error\n",
       "---  -------------------  ----------  -----------------  -------------------  -------------------  ------------------  ------------------  -------------------------------\n",
       "     2018-09-10 13:51:02  0.022 sec   0.0                0.38669841055044796  0.47597036694054895  0.5                 1.0                 0.8169611005750456\n",
       "     2018-09-10 13:51:02  0.764 sec   1.0                0.38476349951235084  0.47107592549311367  0.6582898745388903  2.5923891128070995  0.3376304219236891\n",
       "     2018-09-10 13:51:03  1.026 sec   2.0                0.38316113906448107  0.46716242057962576  0.6641426875319133  2.721845434929714   0.3575466347942215\n",
       "     2018-09-10 13:51:03  1.278 sec   3.0                0.3818189070427441   0.4639557431600399   0.6658225759900159  2.8447857650909363  0.350649746626257\n",
       "     2018-09-10 13:51:03  1.387 sec   4.0                0.38068117430570636  0.46126898984825854  0.6685973490563364  2.9280751977595836  0.3523571990462659\n",
       "---  ---                  ---         ---                ---                  ---                  ---                 ---                 ---\n",
       "     2018-09-10 13:51:05  3.608 sec   23.0               0.37257084918709354  0.4423727361620052   0.693152642203149   3.297979492238286   0.34139291529206583\n",
       "     2018-09-10 13:51:05  3.731 sec   24.0               0.37241485427128135  0.4419880439679489   0.6938719600943855  3.297979492238286   0.3356546555519645\n",
       "     2018-09-10 13:51:06  3.887 sec   25.0               0.3722079560405656   0.44150653867040346  0.694788671172853   3.307973369487493   0.3273674132705641\n",
       "     2018-09-10 13:51:06  4.015 sec   26.0               0.3720655790660898   0.4411388706323857   0.6955962776365582  3.331292416402309   0.33177020129644424\n",
       "     2018-09-10 13:51:07  5.497 sec   50.0               0.3693171354257843   0.43467809200204266  0.7079429892082825  3.521176084137241   0.3125796557044156"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>term</td>\n",
       "<td>2747.9863281</td>\n",
       "<td>1.0</td>\n",
       "<td>0.2493995</td></tr>\n",
       "<tr><td>annual_inc</td>\n",
       "<td>1938.3043213</td>\n",
       "<td>0.7053544</td>\n",
       "<td>0.1759151</td></tr>\n",
       "<tr><td>addr_state</td>\n",
       "<td>1546.3793945</td>\n",
       "<td>0.5627318</td>\n",
       "<td>0.1403451</td></tr>\n",
       "<tr><td>revol_util</td>\n",
       "<td>1427.8056641</td>\n",
       "<td>0.5195825</td>\n",
       "<td>0.1295836</td></tr>\n",
       "<tr><td>purpose</td>\n",
       "<td>934.7630005</td>\n",
       "<td>0.3401629</td>\n",
       "<td>0.0848365</td></tr>\n",
       "<tr><td>dti</td>\n",
       "<td>847.0342407</td>\n",
       "<td>0.3082382</td>\n",
       "<td>0.0768744</td></tr>\n",
       "<tr><td>loan_amnt</td>\n",
       "<td>627.7856445</td>\n",
       "<td>0.2284530</td>\n",
       "<td>0.0569761</td></tr>\n",
       "<tr><td>emp_length</td>\n",
       "<td>249.1807861</td>\n",
       "<td>0.0906776</td>\n",
       "<td>0.0226149</td></tr>\n",
       "<tr><td>home_ownership</td>\n",
       "<td>239.7884827</td>\n",
       "<td>0.0872597</td>\n",
       "<td>0.0217625</td></tr>\n",
       "<tr><td>total_acc</td>\n",
       "<td>163.4083862</td>\n",
       "<td>0.0594648</td>\n",
       "<td>0.0148305</td></tr>\n",
       "<tr><td>delinq_2yrs</td>\n",
       "<td>128.5801697</td>\n",
       "<td>0.0467907</td>\n",
       "<td>0.0116696</td></tr>\n",
       "<tr><td>longest_credit_length</td>\n",
       "<td>117.2748566</td>\n",
       "<td>0.0426767</td>\n",
       "<td>0.0106435</td></tr>\n",
       "<tr><td>verification_status</td>\n",
       "<td>50.1193047</td>\n",
       "<td>0.0182386</td>\n",
       "<td>0.0045487</td></tr></table></div>"
      ],
      "text/plain": [
       "variable               relative_importance    scaled_importance    percentage\n",
       "---------------------  ---------------------  -------------------  ------------\n",
       "term                   2747.99                1                    0.2494\n",
       "annual_inc             1938.3                 0.705354             0.175915\n",
       "addr_state             1546.38                0.562732             0.140345\n",
       "revol_util             1427.81                0.519583             0.129584\n",
       "purpose                934.763                0.340163             0.0848365\n",
       "dti                    847.034                0.308238             0.0768744\n",
       "loan_amnt              627.786                0.228453             0.0569761\n",
       "emp_length             249.181                0.0906776            0.0226149\n",
       "home_ownership         239.788                0.0872597            0.0217625\n",
       "total_acc              163.408                0.0594648            0.0148305\n",
       "delinq_2yrs            128.58                 0.0467907            0.0116696\n",
       "longest_credit_length  117.275                0.0426767            0.0106435\n",
       "verification_status    50.1193                0.0182386            0.00454869"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(gbm_v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Write Script to Calculate Cost Matrix Loss\n",
    "\n",
    "### Function to Calculate Cost Matrix Loss in H2O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CostMatrixLoss(actual, predicted, cost_tp, cost_tn, cost_fp, cost_fn):\n",
    "    c1 = cost_tp + cost_tn - cost_fp - cost_fn\n",
    "    c2 = cost_fn - cost_tn\n",
    "    c3 = cost_fp - cost_tn\n",
    "    c4 = cost_tn\n",
    "\n",
    "    cost = (actual * predicted * c1) + (actual * c2) + (predicted * c3) + c4\n",
    "    mean_cost = cost.mean()[0]\n",
    "    return mean_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n",
      "CostMatrixLoss: 0.5543\n"
     ]
    }
   ],
   "source": [
    "loss_v1 = CostMatrixLoss(train[y].asnumeric(), gbm_v1.predict(train)[\"p1\"], 0, 0, 1, 3)\n",
    "print(\"CostMatrixLoss: \" + str(round(loss_v1, 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Script to calculate Cost Matrix Loss in custom_metric_func\n",
    "\n",
    "The confusion matrix loss metric is defined in a class stored in utils_model_metrics.py. This class contains three methods `map`, `reduce`, and `metric`. The `map` method takes 5 arguments `predicted`, `actual`, `weight`, `offset` and `model`.\n",
    "\n",
    "```\n",
    "class CostMatrixLossMetric:\n",
    "    def map(self, predicted, actual, weight, offset, model):\n",
    "        cost_tp = 0\n",
    "        cost_tn = 0\n",
    "        cost_fp = 1\n",
    "        cost_fn = 3\n",
    "        c1 = cost_tp + cost_tn - cost_fp - cost_fn\n",
    "        c2 = cost_fn - cost_tn\n",
    "        c3 = cost_fp - cost_tn\n",
    "        c4 = cost_tn\n",
    "        y = actual[0]\n",
    "        p = predicted[2] # [class, p0, p1]\n",
    "        return [weight * ((y * p * c1) + (y * c2) + (p * c3) + c4), weight]\n",
    "\n",
    "    def reduce(self, left, right):\n",
    "        return [left[0] + right[0], left[1] + right[1]]\n",
    "\n",
    "    def metric(self, last):\n",
    "        return last[0] / last[1]\n",
    "```\n",
    "\n",
    "This class definition is uploaded to the H2O cluster using [`h2o.upload_custom_metric`](http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/h2o.html?highlight=custom_metric#h2o.upload_custom_metric)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_model_metrics import CostMatrixLossMetric\n",
    "\n",
    "cost_matrix_loss_func = h2o.upload_custom_metric(CostMatrixLossMetric,\n",
    "                                                 func_name = \"CostMatrixLoss\",\n",
    "                                                 func_file = \"cost_matrix_loss.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cost_matrix_loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python:CostMatrixLoss=cost_matrix_loss.CostMatrixLossMetricWrapper\n"
     ]
    }
   ],
   "source": [
    "print(cost_matrix_loss_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train a GBM Model using custom_metric_func\n",
    "\n",
    "The [`H2OGeneralizedLinearEstimator`](http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/modeling.html?highlight=automl#h2ogeneralizedlinearestimator),\n",
    "[`H2ORandomForestEstimator`](http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/modeling.html?highlight=automl#h2orandomforestestimator), and\n",
    "[`H2OGradientBoostingEstimator`](http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/modeling.html?highlight=automl#h2ogradientboostingestimator) models accept a `custom_metric_func` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |███████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# Train GBM Model with custom_metric_function\n",
    "gbm_v2 = H2OGradientBoostingEstimator(model_id = \"gbm_v2.hex\",\n",
    "                                      custom_metric_func = cost_matrix_loss_func)\n",
    "\n",
    "gbm_v2.train(y = y, x = x, training_frame = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.1363951465191071\n",
      "RMSE: 0.3693171354257843\n",
      "LogLoss: 0.43467809200204266\n",
      "Mean Per-Class Error: 0.3508577460272526\n",
      "AUC: 0.7079429892082825\n",
      "Gini: 0.41588597841656494\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.19860658480443358: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>95113.0</td>\n",
       "<td>38858.0</td>\n",
       "<td>0.29</td>\n",
       "<td> (38858.0/133971.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>12401.0</td>\n",
       "<td>17615.0</td>\n",
       "<td>0.4131</td>\n",
       "<td> (12401.0/30016.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>107514.0</td>\n",
       "<td>56473.0</td>\n",
       "<td>0.3126</td>\n",
       "<td> (51259.0/163987.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0       1      Error    Rate\n",
       "-----  ------  -----  -------  ------------------\n",
       "0      95113   38858  0.29     (38858.0/133971.0)\n",
       "1      12401   17615  0.4131   (12401.0/30016.0)\n",
       "Total  107514  56473  0.3126   (51259.0/163987.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.1986066</td>\n",
       "<td>0.4073350</td>\n",
       "<td>228.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1265125</td>\n",
       "<td>0.5633597</td>\n",
       "<td>311.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.2803267</td>\n",
       "<td>0.3837915</td>\n",
       "<td>152.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.4292597</td>\n",
       "<td>0.8203272</td>\n",
       "<td>62.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.7770519</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0438524</td>\n",
       "<td>1.0</td>\n",
       "<td>396.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.7770519</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2251476</td>\n",
       "<td>0.2462816</td>\n",
       "<td>202.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.1823683</td>\n",
       "<td>0.6488206</td>\n",
       "<td>245.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.1920415</td>\n",
       "<td>0.6491423</td>\n",
       "<td>235.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.198607     0.407335  228\n",
       "max f2                       0.126512     0.56336   311\n",
       "max f0point5                 0.280327     0.383791  152\n",
       "max accuracy                 0.42926      0.820327  62\n",
       "max precision                0.777052     1         0\n",
       "max recall                   0.0438524    1         396\n",
       "max specificity              0.777052     1         0\n",
       "max absolute_mcc             0.225148     0.246282  202\n",
       "max min_per_class_accuracy   0.182368     0.648821  245\n",
       "max mean_per_class_accuracy  0.192041     0.649142  235"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate: 18.30 %, avg score: 18.31 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100008</td>\n",
       "<td>0.4806708</td>\n",
       "<td>3.5211761</td>\n",
       "<td>3.5211761</td>\n",
       "<td>0.6445122</td>\n",
       "<td>0.5303616</td>\n",
       "<td>0.6445122</td>\n",
       "<td>0.5303616</td>\n",
       "<td>0.0352146</td>\n",
       "<td>0.0352146</td>\n",
       "<td>252.1176084</td>\n",
       "<td>252.1176084</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200016</td>\n",
       "<td>0.4375856</td>\n",
       "<td>2.8082795</td>\n",
       "<td>3.1647278</td>\n",
       "<td>0.5140244</td>\n",
       "<td>0.4573837</td>\n",
       "<td>0.5792683</td>\n",
       "<td>0.4938727</td>\n",
       "<td>0.0280850</td>\n",
       "<td>0.0632996</td>\n",
       "<td>180.8279507</td>\n",
       "<td>216.4727796</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300024</td>\n",
       "<td>0.4110619</td>\n",
       "<td>2.6750278</td>\n",
       "<td>3.0014945</td>\n",
       "<td>0.4896341</td>\n",
       "<td>0.4234982</td>\n",
       "<td>0.5493902</td>\n",
       "<td>0.4704145</td>\n",
       "<td>0.0267524</td>\n",
       "<td>0.0900520</td>\n",
       "<td>167.5027810</td>\n",
       "<td>200.1494467</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400032</td>\n",
       "<td>0.3902679</td>\n",
       "<td>2.5117945</td>\n",
       "<td>2.8790695</td>\n",
       "<td>0.4597561</td>\n",
       "<td>0.4001474</td>\n",
       "<td>0.5269817</td>\n",
       "<td>0.4528477</td>\n",
       "<td>0.0251199</td>\n",
       "<td>0.1151719</td>\n",
       "<td>151.1794482</td>\n",
       "<td>187.9069471</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.0500040</td>\n",
       "<td>0.3731066</td>\n",
       "<td>2.3019231</td>\n",
       "<td>2.7636402</td>\n",
       "<td>0.4213415</td>\n",
       "<td>0.3814565</td>\n",
       "<td>0.5058537</td>\n",
       "<td>0.4385695</td>\n",
       "<td>0.0230211</td>\n",
       "<td>0.1381930</td>\n",
       "<td>130.1923060</td>\n",
       "<td>176.3640189</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1000018</td>\n",
       "<td>0.3147513</td>\n",
       "<td>2.0763146</td>\n",
       "<td>2.4199984</td>\n",
       "<td>0.3800463</td>\n",
       "<td>0.3412588</td>\n",
       "<td>0.4429538</td>\n",
       "<td>0.3899171</td>\n",
       "<td>0.1038113</td>\n",
       "<td>0.2420043</td>\n",
       "<td>107.6314643</td>\n",
       "<td>141.9998372</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.1499997</td>\n",
       "<td>0.2770929</td>\n",
       "<td>1.7224882</td>\n",
       "<td>2.1875044</td>\n",
       "<td>0.3152824</td>\n",
       "<td>0.2946252</td>\n",
       "<td>0.4003984</td>\n",
       "<td>0.3581544</td>\n",
       "<td>0.0861207</td>\n",
       "<td>0.328125</td>\n",
       "<td>72.2488239</td>\n",
       "<td>118.7504446</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2000037</td>\n",
       "<td>0.2503682</td>\n",
       "<td>1.5570461</td>\n",
       "<td>2.0298802</td>\n",
       "<td>0.285</td>\n",
       "<td>0.2631637</td>\n",
       "<td>0.3715470</td>\n",
       "<td>0.3344053</td>\n",
       "<td>0.0778585</td>\n",
       "<td>0.4059835</td>\n",
       "<td>55.7046075</td>\n",
       "<td>102.9880242</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.2999994</td>\n",
       "<td>0.2116632</td>\n",
       "<td>1.2990293</td>\n",
       "<td>1.7862732</td>\n",
       "<td>0.2377729</td>\n",
       "<td>0.2298703</td>\n",
       "<td>0.3269575</td>\n",
       "<td>0.2995617</td>\n",
       "<td>0.1298974</td>\n",
       "<td>0.5358809</td>\n",
       "<td>29.9029331</td>\n",
       "<td>78.6273176</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4000012</td>\n",
       "<td>0.1833189</td>\n",
       "<td>1.0747405</td>\n",
       "<td>1.6083873</td>\n",
       "<td>0.1967193</td>\n",
       "<td>0.1968137</td>\n",
       "<td>0.2943974</td>\n",
       "<td>0.2738743</td>\n",
       "<td>0.1074760</td>\n",
       "<td>0.6433569</td>\n",
       "<td>7.4740466</td>\n",
       "<td>60.8387287</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5000030</td>\n",
       "<td>0.1606487</td>\n",
       "<td>0.9334851</td>\n",
       "<td>1.4734052</td>\n",
       "<td>0.1708641</td>\n",
       "<td>0.1716489</td>\n",
       "<td>0.2696905</td>\n",
       "<td>0.2534290</td>\n",
       "<td>0.0933502</td>\n",
       "<td>0.7367071</td>\n",
       "<td>-6.6514945</td>\n",
       "<td>47.3405194</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.5999988</td>\n",
       "<td>0.1407404</td>\n",
       "<td>0.7786180</td>\n",
       "<td>1.3576120</td>\n",
       "<td>0.1425174</td>\n",
       "<td>0.1504536</td>\n",
       "<td>0.2484958</td>\n",
       "<td>0.2362671</td>\n",
       "<td>0.0778585</td>\n",
       "<td>0.8145656</td>\n",
       "<td>-22.1382009</td>\n",
       "<td>35.7612035</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7000006</td>\n",
       "<td>0.1230032</td>\n",
       "<td>0.6626345</td>\n",
       "<td>1.2583278</td>\n",
       "<td>0.1212879</td>\n",
       "<td>0.1318218</td>\n",
       "<td>0.2303229</td>\n",
       "<td>0.2213461</td>\n",
       "<td>0.0662647</td>\n",
       "<td>0.8808302</td>\n",
       "<td>-33.7365534</td>\n",
       "<td>25.8327795</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.7999963</td>\n",
       "<td>0.1056462</td>\n",
       "<td>0.5434001</td>\n",
       "<td>1.1689652</td>\n",
       "<td>0.0994633</td>\n",
       "<td>0.1142765</td>\n",
       "<td>0.2139661</td>\n",
       "<td>0.2079629</td>\n",
       "<td>0.0543377</td>\n",
       "<td>0.9351679</td>\n",
       "<td>-45.6599939</td>\n",
       "<td>16.8965234</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.8999982</td>\n",
       "<td>0.0862040</td>\n",
       "<td>0.4147712</td>\n",
       "<td>1.0851642</td>\n",
       "<td>0.0759193</td>\n",
       "<td>0.0963432</td>\n",
       "<td>0.1986273</td>\n",
       "<td>0.1955604</td>\n",
       "<td>0.0414779</td>\n",
       "<td>0.9766458</td>\n",
       "<td>-58.5228803</td>\n",
       "<td>8.5164193</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0315070</td>\n",
       "<td>0.2335378</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0427465</td>\n",
       "<td>0.0711412</td>\n",
       "<td>0.1830389</td>\n",
       "<td>0.1831183</td>\n",
       "<td>0.0233542</td>\n",
       "<td>1.0</td>\n",
       "<td>-76.6462161</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift      cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  --------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.0100008                   0.480671           3.52118   3.52118            0.644512         0.530362   0.644512                    0.530362            0.0352146       0.0352146                  252.118   252.118\n",
       "    2        0.0200016                   0.437586           2.80828   3.16473            0.514024         0.457384   0.579268                    0.493873            0.028085        0.0632996                  180.828   216.473\n",
       "    3        0.0300024                   0.411062           2.67503   3.00149            0.489634         0.423498   0.54939                     0.470414            0.0267524       0.090052                   167.503   200.149\n",
       "    4        0.0400032                   0.390268           2.51179   2.87907            0.459756         0.400147   0.526982                    0.452848            0.0251199       0.115172                   151.179   187.907\n",
       "    5        0.050004                    0.373107           2.30192   2.76364            0.421341         0.381456   0.505854                    0.438569            0.0230211       0.138193                   130.192   176.364\n",
       "    6        0.100002                    0.314751           2.07631   2.42               0.380046         0.341259   0.442954                    0.389917            0.103811        0.242004                   107.631   142\n",
       "    7        0.15                        0.277093           1.72249   2.1875             0.315282         0.294625   0.400398                    0.358154            0.0861207       0.328125                   72.2488   118.75\n",
       "    8        0.200004                    0.250368           1.55705   2.02988            0.285            0.263164   0.371547                    0.334405            0.0778585       0.405983                   55.7046   102.988\n",
       "    9        0.299999                    0.211663           1.29903   1.78627            0.237773         0.22987    0.326957                    0.299562            0.129897        0.535881                   29.9029   78.6273\n",
       "    10       0.400001                    0.183319           1.07474   1.60839            0.196719         0.196814   0.294397                    0.273874            0.107476        0.643357                   7.47405   60.8387\n",
       "    11       0.500003                    0.160649           0.933485  1.47341            0.170864         0.171649   0.26969                     0.253429            0.0933502       0.736707                   -6.65149  47.3405\n",
       "    12       0.599999                    0.14074            0.778618  1.35761            0.142517         0.150454   0.248496                    0.236267            0.0778585       0.814566                   -22.1382  35.7612\n",
       "    13       0.700001                    0.123003           0.662634  1.25833            0.121288         0.131822   0.230323                    0.221346            0.0662647       0.88083                    -33.7366  25.8328\n",
       "    14       0.799996                    0.105646           0.5434    1.16897            0.0994633        0.114276   0.213966                    0.207963            0.0543377       0.935168                   -45.66    16.8965\n",
       "    15       0.899998                    0.086204           0.414771  1.08516            0.0759193        0.0963432  0.198627                    0.19556             0.0414779       0.976646                   -58.5229  8.51642\n",
       "    16       1                           0.031507           0.233538  1                  0.0427465        0.0711412  0.183039                    0.183118            0.0233542       1                          -76.6462  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CostMatrixLoss: 0.5543038365540239\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf = gbm_v2.model_performance()\n",
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CostMatrixLoss'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf.custom_metric_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5543038365540239"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf.custom_metric_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can see that our custom cost matrix loss function is in the model performance metrics labeled `CostMatrixLoss`.  This value matches the value calculated in our original GBM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost Matrix Loss V1: 0.5543\n",
      "Cost Matrix Loss V2: 0.5543\n"
     ]
    }
   ],
   "source": [
    "print(\"Cost Matrix Loss V1: \" + str(round(loss_v1, 4)))\n",
    "print(\"Cost Matrix Loss V2: \" + str(round(gbm_v2.model_performance().custom_metric_value(), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train a Grid of GBMs and choose model based on custom loss metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Grid Build progress: |████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "from h2o.grid.grid_search import H2OGridSearch\n",
    "gbm_hyper_parameters = {'max_depth': [4, 5, 6]}\n",
    "gbm_grid = H2OGridSearch(H2OGradientBoostingEstimator(custom_metric_func = cost_matrix_loss_func,\n",
    "                                                      nfolds = 5),\n",
    "                           gbm_hyper_parameters)\n",
    "gbm_grid.train(x = x, y = y, training_frame = train, grid_id = \"gbm_grid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.5569432815873339, 'gbm_grid_model_2'],\n",
       " [0.5617845741639093, 'gbm_grid_model_0'],\n",
       " [0.5645126062055483, 'gbm_grid_model_1']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([[h2o.get_model(x).model_performance(xval = True).custom_metric_value(), x] for x in gbm_grid.model_ids])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shutdown H2O Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H2O session _sid_a53c closed.\n"
     ]
    }
   ],
   "source": [
    "h2o.cluster().shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
